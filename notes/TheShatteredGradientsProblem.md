Pretty cool paper. This investigates the problem of why skip connections allow for deeper networks. The answer they come up with is that the gradients across a mini-batch show some correlation in networks with skip connections, while showing little in other networks, thus allowing skip connected networks to have informative gradient moves from a mini batch. They also talk about an initialization strategy that all has this good behavior. 
