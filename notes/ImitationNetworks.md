Imitation learning. Pretty clever paper. So this is an extension to knowledge distillation. You have two things 1) a limited set of training examples, 2) a pertained network on a similar task. You then have two losses. One for how well the new network does on the training examples and another for how well the new network imitates the other. The extension they added was to generate a set of pseudo data points (in a similar way that is done for creating adversarial examples). Pretty cool paper.
