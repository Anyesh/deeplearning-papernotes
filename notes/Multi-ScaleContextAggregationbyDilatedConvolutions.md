This one is a Fisher Yu Princeton work, that I really quite enjoyed. You might even be slightly familiar with this work from other papers principally wavenet that used a 1D dilated convolution. But the idea is incredibly simple. Convolution layer receptive fields increase linearly with the layer that they are. That means to encorporate all the context information of the image the number of convolutional layers will need to be linear in the size of the image. Dilated convolutions can increase the receptive field exponentially, thereby incorporate more context. They do some results on image segmentation to pretty good success, and all in all I am very excited to try these out myself
