## 2017 February 

* Graphical models and message-passing algorithms: Some introductory lectures [[Berkeley](https://people.eecs.berkeley.edu/~wainwrig/Graphical/Wai12_Basics.pdf)]
* Hierarchical Bayesian inference in the visual cortex [[CMU](http://www.cnbc.cmu.edu/~tai/papers/lee_mumford_josa.pdf)]
* 3-D Depth Reconstruction from a Single Still Image [[Cornell](http://www.cs.cornell.edu/~asaxena/learningdepth/saxena_ijcv07_learningdepth.pdf)]

## 2017 January
* Deep Learning (Convoluational NN) [[MIT Press](http://www.deeplearningbook.org/)]

## 2016 December
* Rationalizing Neural Predictions [[arXiv](https://arxiv.org/pdf/1606.04155.pdf)]
* Using “Annotator Rationales” to Improve Machine Learning for Text Categorization [[JHU](https://www.cs.jhu.edu/~jason/papers/zaidan+al.naacl07.pdf)]

## 2016 September
* Why does deep and cheap learning work so well? [[arXiv](http://arxiv.org/pdf/1608.08225v1.pdf)]

## 2016 August
* Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks [[arXiv](https://arxiv.org/pdf/1506.05751.pdf)]
* Exploring the Limits of Language Modeling [[arXiv](http://arxiv.org/pdf/1602.02410v2.pdf)]
* Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering [[arXiv](http://arxiv.org/pdf/1607.06275v1.pdf)]
* Recurrent Models of Visual Attention [[arXiv](https://arxiv.org/pdf/1406.6247v1.pdf)]
* Playing Atari with Deep Reinforcement Learning [[Toronto](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)]
* InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets [[arXiv](https://arxiv.org/pdf/1606.03657v1.pdf)]
* Improved Techniques for Training GANs [[arXiv](https://arxiv.org/pdf/1606.03498v1.pdf)]
* Neural Turing Machines [[arXiv](https://arxiv.org/pdf/1410.5401v2.pdf)]
* Harnessing Deep Neural Networks with Logic Rules [[arXiv](http://arxiv.org/pdf/1603.06318v3.pdf)]
* Random Search for Hyper-Parameter Optimization [[JMLR](http://jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)]
* Going Deeper with Convolutions [[CVF](http://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf)]
* Visualizing and Understanding Convolutional Networks [[arXiv](https://arxiv.org/pdf/1311.2901v3.pdf)]
* Bag of Tricks for Efficient Text Classification [[arXiv](http://arxiv.org/pdf/1607.01759v3.pdf)]
* A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task [[arXiv](http://arxiv.org/pdf/1606.02858v2.pdf)]
* Full Resolution Image Compression with Recurrent Neural Networks [[arXiv](https://arxiv.org/pdf/1608.05148v1.pdf)]
* Neural Module Networks [[arXiv](http://arxiv.org/pdf/1511.02799.pdf)]
* Deep Residual Learning for Image Recognition [[arXiv](https://arxiv.org/pdf/1512.03385v1.pdf)]
* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [[arXiv](https://arxiv.org/pdf/1502.03167v3.pdf)]
* Memory Networks [[arXiv](http://arxiv.org/pdf/1410.3916v11.pdf)]
* Natural Language Comprehension with the EpiReader [[arXiv](http://arxiv.org/pdf/1606.02270v2.pdf)]
* Learning to Compose Neural Networks for Question Answering [[arXiv](http://arxiv.org/pdf/1601.01705.pdf)]
* LSTM: A Search Space Odyssey [[arXiv](http://arxiv.org/pdf/1503.04069v1.pdf)]
* Deep Networks with Stochastic Depth [[arXiv](http://arxiv.org/pdf/1603.09382v1.pdf)]
* Open AI Research #1 [[Link](https://openai.com/blog/generative-models/)]
* Human tests of materials for the Winograd Schema
Challenge 2016 [[NYU](http://www.cs.nyu.edu/~davise/papers/WS2016SubjectTests.pdf)]

## 2016 July

* Deep Learning (Chapters up to Regularization) [[MIT Press](http://www.deeplearningbook.org/)]
* You Only Die Once: Counting Common Sense for Coreference [Unpublished]
* A PDTB-Styled End-to-End Discourse Parser [[NUS](https://www.comp.nus.edu.sg/~nght/pubs/nle13.pdf)]
* Shallow Convolutional Neural Network for Implicit Discourse Relation Recognition [[emnlp](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP266.pdf)]
* Recursive Deep Models for Discourse Parsing [[stanford](http://web.stanford.edu/~jiweil/paper/discourse_ed.pdf)]

## 2016 June

* Key-Value Memory Networks for Directly Reading Documents [[arXiv](https://arxiv.org/pdf/1606.03126v1.pdf)]
* Learning to learn by gradient descent by gradient descent [[arXiv](https://arxiv.org/abs/1606.04474)]
* Multilingual Language Processing From Bytes [[arXiv](https://arxiv.org/abs/1512.00103)]
* Learning to Communicate with Deep Multi-Agent Reinforcement Learning [[arXiv](https://arxiv.org/abs/1605.06676)]
* Iterative Alternating Neural Attention for Machine Reading [[arXiv](https://arxiv.org/abs/1606.02245)]
* Gated-Attention Readers for Text Comprehension [[arXiv](https://arxiv.org/abs/1606.01549)]

## 2016 Pre-June

* Globally Normalized Transition-Based Neural Networks [[arXiv](https://arxiv.org/abs/1603.06042)]
* Adaptive Computation Time for Recurrent Neural Networks [[arXiv](https://arxiv.org/abs/1603.08983)]
* Neural Machine Translation by Jointly Learning to Align and Translate [[arXiv](https://arxiv.org/abs/1409.0473)]
* Alpha Go

## 2015

* Conditional Random Fields as Recurrent Neural Networks [[arXiv](https://arxiv.org/pdf/1502.03240.pdf)]
* Skip-Thought Vectors [[arXiv](http://arxiv.org/abs/1506.06726)]
* Distributed Representations of Sentences and Documents [[arXiv](https://arxiv.org/abs/1405.4053)]
* A Neural Algorithm of Artistic Style [[arXiv](http://arxiv.org/abs/1508.06576)]
* Intriguing properties of neural networks [[arXiv](https://arxiv.org/abs/1312.6199)]
* Difference Target Propagation [[arXiv](http://arxiv.org/abs/1412.7525)]
* Long Short-Term Memory [[cmu](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)]
